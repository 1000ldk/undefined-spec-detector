"""
LLMæ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: OpenAI GPT-4oã‚’ä½¿ç”¨ã—ãŸæœªå®šç¾©è¦ç´ æ¤œå‡º
"""
import json
import time
from typing import List, Dict, Any, Optional
from datetime import datetime
import uuid

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from usd.schema import (
    UndefinedElement,
    Question,
    DetectionInfo,
    Context,
    Priority,
)


class LLMUnknownTermDetector:
    """æœªçŸ¥ã®ç”¨èªã‚’æ¤œå‡ºã™ã‚‹LLMã‚¯ãƒ©ã‚¹"""
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ1: æœªçŸ¥ã®ç”¨èªæ¤œå‡ºç”¨
    SYSTEM_PROMPT = """ã‚ãªãŸã¯è¦ä»¶å®šç¾©ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦ä»¶æ–‡ã‹ã‚‰ã€å®šç¾©ãŒä¸æ˜ç¢ºãªç”¨èªãƒ»æ¦‚å¿µã‚’å…¨ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

æŠ½å‡ºåŸºæº–:
1. å›ºæœ‰åè©ã‚„å°‚é–€ç”¨èªã§ã€æ–‡ä¸­ã§å®šç¾©ã•ã‚Œã¦ã„ãªã„ã‚‚ã®
2. ä¸€èˆ¬çš„ã§ãªã„ç•¥èªã‚„é€ èªï¼ˆä¾‹ï¼šAPIã€ECã‚µã‚¤ãƒˆã¯ä¸€èˆ¬çš„ãªã®ã§é™¤å¤–ï¼‰
3. ã‚·ã‚¹ãƒ†ãƒ åã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåã§è©³ç´°ãŒä¸æ˜ãªã‚‚ã®
4. ã€Œæ—¢å­˜ã®ã€œã€ã€Œç¤¾å†…ã®ã€œã€ãªã©å¤–éƒ¨å‚ç…§ã—ã¦ã„ã‚‹ãŒè©³ç´°ä¸æ˜ã®ã‚‚ã®
5. å…·ä½“æ€§ã‚’æ¬ ãè¡¨ç¾ï¼ˆã€Œã€œçš„ãªã‚‚ã®ã€ã€Œã€œã®ã‚ˆã†ãªã€ç­‰ï¼‰

é™¤å¤–ã™ã¹ãã‚‚ã®:
- ä¸€èˆ¬çš„ãªITç”¨èªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚·ã‚¹ãƒ†ãƒ ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€APIã€ã‚µãƒ¼ãƒãƒ¼ç­‰ï¼‰
- æ–‡ä¸­ã§æ—¢ã«å®šç¾©ãƒ»èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®
- èª°ã§ã‚‚ç†è§£ã§ãã‚‹ä¸€èˆ¬ç”¨èª

å‡ºåŠ›å½¢å¼: å¿…ãšJSONå½¢å¼
{
  "unknown_terms": [
    {
      "term": "ç”¨èªå",
      "context": "ãã®ç”¨èªãŒä½¿ã‚ã‚Œã¦ã„ã‚‹æ–‡ã®ä¸€éƒ¨",
      "confidence": 0.95,
      "reasoning": "ãªãœã“ã‚ŒãŒæœªå®šç¾©ã¨åˆ¤æ–­ã—ãŸã‹ï¼ˆ50æ–‡å­—ç¨‹åº¦ï¼‰",
      "questions": [
        "ã“ã®ç”¨èªã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®è³ªå•1",
        "è³ªå•2",
        "è³ªå•3"
      ]
    }
  ]
}"""
    
    USER_PROMPT_TEMPLATE = """ä»¥ä¸‹ã®è¦ä»¶æ–‡ã‚’åˆ†æã—ã¦ãã ã•ã„:

{requirement_text}"""
    
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o",
        max_cost: float = 1.00,
        timeout: int = 30
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: OpenAI API Key
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4oï¼‰
            max_cost: ã‚³ã‚¹ãƒˆä¸Šé™ï¼ˆUSDã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: $1.00ï¼‰
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30ç§’ï¼‰
        """
        if not OPENAI_AVAILABLE:
            raise ImportError("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install openai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        self.client = OpenAI(api_key=api_key, timeout=timeout)
        self.model = model
        self.max_cost = max_cost
        self.timeout = timeout
        self.total_cost = 0.0
        self.call_count = 0
        
        # ãƒˆãƒ¼ã‚¯ãƒ³å˜ä¾¡ï¼ˆGPT-4o 2024å¹´1æœˆæ™‚ç‚¹ã®æ¦‚ç®—ï¼‰
        self.price_per_1k_input = 0.005  # $0.005 per 1K input tokens
        self.price_per_1k_output = 0.015  # $0.015 per 1K output tokens
    
    def detect_unknown_terms(self, requirement_text: str) -> List[UndefinedElement]:
        """
        æœªçŸ¥ã®ç”¨èªã‚’æ¤œå‡º
        
        Args:
            requirement_text: è¦ä»¶æ–‡
        
        Returns:
            æœªå®šç¾©è¦ç´ ã®ãƒªã‚¹ãƒˆ
        
        Raises:
            Exception: APIå‘¼ã³å‡ºã—å¤±æ•—æ™‚
        """
        # ã‚³ã‚¹ãƒˆä¸Šé™ãƒã‚§ãƒƒã‚¯
        if self.total_cost >= self.max_cost:
            raise Exception(f"ã‚³ã‚¹ãƒˆä¸Šé™ï¼ˆ${self.max_cost}ï¼‰ã‚’è¶…éã—ã¾ã—ãŸã€‚ç¾åœ¨ã®ã‚³ã‚¹ãƒˆ: ${self.total_cost:.4f}")
        
        try:
            start_time = time.time()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
            user_prompt = self.USER_PROMPT_TEMPLATE.format(
                requirement_text=requirement_text
            )
            
            print(f"\nğŸ¤– LLMï¼ˆ{self.model}ï¼‰ã§æœªçŸ¥ã®ç”¨èªã‚’æ¤œå‡ºä¸­...")
            
            # APIå‘¼ã³å‡ºã—
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=2000
            )
            
            elapsed_time = time.time() - start_time
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—
            content = response.choices[0].message.content
            
            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¨˜éŒ²
            usage = response.usage
            input_tokens = usage.prompt_tokens
            output_tokens = usage.completion_tokens
            
            # ã‚³ã‚¹ãƒˆã®è¨ˆç®—
            cost = (input_tokens / 1000 * self.price_per_1k_input +
                   output_tokens / 1000 * self.price_per_1k_output)
            self.total_cost += cost
            self.call_count += 1
            
            print(f"âœ“ å®Œäº†ï¼ˆ{elapsed_time:.1f}ç§’ï¼‰")
            print(f"  å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {input_tokens}, å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {output_tokens}")
            print(f"  ã‚³ã‚¹ãƒˆ: ${cost:.4f} (ç´¯è¨ˆ: ${self.total_cost:.4f})")
            
            # JSONã®ãƒ‘ãƒ¼ã‚¹
            try:
                result = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON parseå¤±æ•—: {e}")
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content[:200]}")
                return []
            
            # UndefinedElementã«å¤‰æ›
            elements = []
            for term_data in result.get("unknown_terms", []):
                element = self._convert_to_undefined_element(
                    term_data,
                    requirement_text
                )
                elements.append(element)
            
            print(f"âœ“ {len(elements)}å€‹ã®æœªçŸ¥ã®ç”¨èªã‚’æ¤œå‡º")
            
            return elements
        
        except Exception as e:
            print(f"âŒ LLMæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _convert_to_undefined_element(
        self,
        term_data: Dict[str, Any],
        requirement_text: str
    ) -> UndefinedElement:
        """
        LLMæ¤œå‡ºçµæœã‚’UndefinedElementã«å¤‰æ›
        
        Args:
            term_data: LLMã‹ã‚‰ã®ç”¨èªãƒ‡ãƒ¼ã‚¿
            requirement_text: å…ƒã®è¦ä»¶æ–‡
        
        Returns:
            UndefinedElement
        """
        term = term_data.get("term", "ä¸æ˜ãªç”¨èª")
        context_text = term_data.get("context", "")
        confidence = term_data.get("confidence", 0.5)
        reasoning = term_data.get("reasoning", "")
        question_texts = term_data.get("questions", [])
        
        # Questionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        questions = []
        for q_text in question_texts:
            questions.append(
                Question(
                    text=q_text,
                    type="clarification"
                )
            )
        
        # Contextã®ä½œæˆ
        context = Context(
            source_text=term,
            surrounding_text=context_text if context_text else requirement_text[:100],
            line_number=1
        )
        
        # ä¿¡é ¼åº¦ã«åŸºã¥ãé‡è¦åº¦ã®æ±ºå®š
        if confidence >= 0.9:
            priority = Priority.HIGH
        elif confidence >= 0.7:
            priority = Priority.MEDIUM
        else:
            priority = Priority.LOW
        
        return UndefinedElement(
            id=f"LLM-{uuid.uuid4().hex[:8].upper()}",
            category="æœªçŸ¥ã®ç”¨èªãƒ»æ¦‚å¿µ",
            subcategory="å®šç¾©æ¬ è½",
            title=f"ã€Œ{term}ã€ã®å®šç¾©ãŒä¸æ˜",
            description=reasoning if reasoning else f"ã€Œ{term}ã€ã¯æ–‡ä¸­ã§å®šç¾©ã•ã‚Œã¦ãŠã‚‰ãšã€æ„å‘³ãŒä¸æ˜ç¢ºã§ã™ã€‚",
            questions=questions,
            detection=DetectionInfo(
                method="llm",
                confidence=confidence,
                reasoning=f"LLMï¼ˆ{self.model}ï¼‰ã«ã‚ˆã‚‹æ¤œå‡º: {reasoning}"
            ),
            context=context,
            estimated_severity=priority
        )


class LLMContextualAmbiguityDetector:
    """æ–‡è„ˆä¾å­˜ã®æ›–æ˜§ã•ã‚’æ¤œå‡ºã™ã‚‹LLMã‚¯ãƒ©ã‚¹"""
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ2: æ–‡è„ˆä¾å­˜ã®æ›–æ˜§ã•æ¤œå‡ºç”¨
    SYSTEM_PROMPT = """ã‚ãªãŸã¯è¦ä»¶å®šç¾©ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚ã“ã®è¦ä»¶ã‚’å®Ÿè£…ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒã€Œã“ã‚Œã ã‘ã§ã¯å®Ÿè£…ã§ããªã„ã€ã€Œåˆ¤æ–­ã«è¿·ã†ã€ã¨å›°ã‚‹ç‚¹ã‚’å…¨ã¦æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚

åˆ†æè¦³ç‚¹:
1. æŒ¯ã‚‹èˆã„ã®æ›–æ˜§ã•
   - ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆã„ã¤å®Ÿè¡Œï¼Ÿï¼‰
   - æ¡ä»¶ï¼ˆã©ã†ã„ã†å ´åˆã«ï¼Ÿï¼‰
   - é »åº¦ï¼ˆã©ã®ãã‚‰ã„ã®é »åº¦ã§ï¼Ÿï¼‰

2. çŠ¶æ³èª¬æ˜ã®ä¸è¶³
   - ã€Œã€œãŒèµ·ãã‚‹ã€â†’ ã©ã®ç¨‹åº¦ï¼Ÿå¸¸ã«ï¼Ÿæ¡ä»¶ã¯ï¼Ÿ
   - å•é¡Œã®å†ç¾æ¡ä»¶ãŒä¸æ˜
   - ã‚¨ãƒ©ãƒ¼ãªã®ã‹ã€é…ã„ã®ã‹ã€å‹•ã‹ãªã„ã®ã‹æ›–æ˜§

3. è§£æ±ºç­–ã®å…·ä½“æ€§æ¬ å¦‚
   - ã€Œã€œã™ã‚‹äºˆå®šã€ã€Œã€œã—ã‚ˆã†ã¨æ€ã£ã¦ã„ã‚‹ã€â†’ å…·ä½“çš„ãªæ–¹æ³•ã¯ï¼Ÿ
   - ä»£æ›¿æ¡ˆã®æœ‰ç„¡
   - åˆ¶ç´„æ¡ä»¶ãŒä¸æ˜

4. å¢ƒç•Œæ¡ä»¶ãƒ»ç’°å¢ƒä¾å­˜
   - å¯¾è±¡ãƒ‡ãƒã‚¤ã‚¹ãƒ»ãƒ–ãƒ©ã‚¦ã‚¶ãƒ»OSã®ç¯„å›²
   - ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼ˆæœ€å¤§å€¤ã€æœ€å°å€¤ã€ã‚¼ãƒ­ã€nullç­‰ï¼‰

5. ã‚¨ãƒ©ãƒ¼å‡¦ç†
   - å¤±æ•—ã—ãŸå ´åˆã®æŒ™å‹•
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯

å‡ºåŠ›å½¢å¼: JSON
{
  "contextual_ambiguities": [
    {
      "category": "æŒ¯ã‚‹èˆã„ã®æ›–æ˜§ã• | çŠ¶æ³èª¬æ˜ã®ä¸è¶³ | è§£æ±ºç­–ã®å…·ä½“æ€§æ¬ å¦‚ | å¢ƒç•Œæ¡ä»¶ãƒ»ç’°å¢ƒä¾å­˜ | ã‚¨ãƒ©ãƒ¼å‡¦ç†",
      "issue": "å•é¡Œã®è¦ç´„ï¼ˆ30æ–‡å­—ä»¥å†…ï¼‰",
      "quoted_text": "è¦ä»¶æ–‡ã‹ã‚‰ã®è©²å½“ç®‡æ‰€ã®å¼•ç”¨",
      "explanation": "ãªãœå•é¡Œã‹ã€å®Ÿè£…æ™‚ã«ä½•ãŒå›°ã‚‹ã‹ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰",
      "missing_information": [
        "ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±1",
        "ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±2",
        "ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±3"
      ],
      "clarification_questions": [
        "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒç¢ºèªã™ã¹ãå…·ä½“çš„ãªè³ªå•1",
        "è³ªå•2",
        "è³ªå•3"
      ],
      "potential_risks": [
        "ã“ã®ã¾ã¾å®Ÿè£…ã—ãŸå ´åˆã®ãƒªã‚¹ã‚¯1",
        "ãƒªã‚¹ã‚¯2"
      ],
      "severity": "critical | high | medium | low"
    }
  ]
}"""
    
    USER_PROMPT_TEMPLATE = """è¦ä»¶æ–‡:
{requirement_text}

æ—¢ã«ä»–ã®æ–¹æ³•ã§æ¤œå‡ºæ¸ˆã¿ã®å•é¡Œï¼ˆã“ã‚Œã‚‰ã¯é™¤å¤–ã—ã¦ãã ã•ã„ï¼‰:
{already_detected_issues}"""
    
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o",
        max_cost: float = 1.00,
        timeout: int = 30
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: OpenAI API Key
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            max_cost: ã‚³ã‚¹ãƒˆä¸Šé™ï¼ˆUSDï¼‰
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰
        """
        if not OPENAI_AVAILABLE:
            raise ImportError("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        
        self.client = OpenAI(api_key=api_key, timeout=timeout)
        self.model = model
        self.max_cost = max_cost
        self.timeout = timeout
        self.total_cost = 0.0
        self.call_count = 0
        
        self.price_per_1k_input = 0.005
        self.price_per_1k_output = 0.015
    
    def detect_ambiguities(
        self,
        requirement_text: str,
        already_detected: List[UndefinedElement] = None
    ) -> List[UndefinedElement]:
        """
        æ–‡è„ˆä¾å­˜ã®æ›–æ˜§ã•ã‚’æ¤œå‡º
        
        Args:
            requirement_text: è¦ä»¶æ–‡
            already_detected: æ—¢ã«æ¤œå‡ºæ¸ˆã¿ã®æœªå®šç¾©è¦ç´ ï¼ˆé‡è¤‡å›é¿ç”¨ï¼‰
        
        Returns:
            æœªå®šç¾©è¦ç´ ã®ãƒªã‚¹ãƒˆ
        """
        # ã‚³ã‚¹ãƒˆä¸Šé™ãƒã‚§ãƒƒã‚¯
        if self.total_cost >= self.max_cost:
            raise Exception(f"ã‚³ã‚¹ãƒˆä¸Šé™ï¼ˆ${self.max_cost}ï¼‰ã‚’è¶…éã—ã¾ã—ãŸã€‚")
        
        try:
            start_time = time.time()
            
            # æ—¢æ¤œå‡ºã®å•é¡Œã‚’æ–‡å­—åˆ—åŒ–
            detected_issues_str = "ãªã—"
            if already_detected:
                issues = [f"- {elem.title}" for elem in already_detected[:10]]
                detected_issues_str = "\n".join(issues)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
            user_prompt = self.USER_PROMPT_TEMPLATE.format(
                requirement_text=requirement_text,
                already_detected_issues=detected_issues_str
            )
            
            print(f"\nğŸ¤– LLMï¼ˆ{self.model}ï¼‰ã§æ–‡è„ˆä¾å­˜ã®æ›–æ˜§ã•ã‚’æ¤œå‡ºä¸­...")
            
            # APIå‘¼ã³å‡ºã—
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=2000
            )
            
            elapsed_time = time.time() - start_time
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—
            content = response.choices[0].message.content
            
            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¨˜éŒ²
            usage = response.usage
            input_tokens = usage.prompt_tokens
            output_tokens = usage.completion_tokens
            
            # ã‚³ã‚¹ãƒˆã®è¨ˆç®—
            cost = (input_tokens / 1000 * self.price_per_1k_input +
                   output_tokens / 1000 * self.price_per_1k_output)
            self.total_cost += cost
            self.call_count += 1
            
            print(f"âœ“ å®Œäº†ï¼ˆ{elapsed_time:.1f}ç§’ï¼‰")
            print(f"  å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {input_tokens}, å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {output_tokens}")
            print(f"  ã‚³ã‚¹ãƒˆ: ${cost:.4f} (ç´¯è¨ˆ: ${self.total_cost:.4f})")
            
            # JSONã®ãƒ‘ãƒ¼ã‚¹
            try:
                result = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON parseå¤±æ•—: {e}")
                return []
            
            # UndefinedElementã«å¤‰æ›
            elements = []
            for amb_data in result.get("contextual_ambiguities", []):
                element = self._convert_to_undefined_element(
                    amb_data,
                    requirement_text
                )
                elements.append(element)
            
            print(f"âœ“ {len(elements)}å€‹ã®æ›–æ˜§ã•ã‚’æ¤œå‡º")
            
            return elements
        
        except Exception as e:
            print(f"âŒ LLMæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _convert_to_undefined_element(
        self,
        amb_data: Dict[str, Any],
        requirement_text: str
    ) -> UndefinedElement:
        """
        LLMæ¤œå‡ºçµæœã‚’UndefinedElementã«å¤‰æ›
        """
        category_map = {
            "æŒ¯ã‚‹èˆã„ã®æ›–æ˜§ã•": "æŒ¯ã‚‹èˆã„ã®æ›–æ˜§ã•",
            "çŠ¶æ³èª¬æ˜ã®ä¸è¶³": "éæ©Ÿèƒ½è¦ä»¶ã®æ›–æ˜§ã•",
            "è§£æ±ºç­–ã®å…·ä½“æ€§æ¬ å¦‚": "æŒ¯ã‚‹èˆã„ã®æ›–æ˜§ã•",
            "å¢ƒç•Œæ¡ä»¶ãƒ»ç’°å¢ƒä¾å­˜": "å¢ƒç•Œæ¡ä»¶ã®æœªå®šç¾©",
            "ã‚¨ãƒ©ãƒ¼å‡¦ç†": "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ¬ è½"
        }
        
        category_raw = amb_data.get("category", "æŒ¯ã‚‹èˆã„ã®æ›–æ˜§ã•")
        category = category_map.get(category_raw, "éæ©Ÿèƒ½è¦ä»¶ã®æ›–æ˜§ã•")
        issue = amb_data.get("issue", "è¦ä»¶ã®æ›–æ˜§ã•")
        quoted_text = amb_data.get("quoted_text", "")
        explanation = amb_data.get("explanation", "")
        missing_info = amb_data.get("missing_information", [])
        questions_raw = amb_data.get("clarification_questions", [])
        risks = amb_data.get("potential_risks", [])
        severity_str = amb_data.get("severity", "medium")
        
        # é‡è¦åº¦ã®å¤‰æ›
        severity_map = {
            "critical": Priority.CRITICAL,
            "high": Priority.HIGH,
            "medium": Priority.MEDIUM,
            "low": Priority.LOW
        }
        priority = severity_map.get(severity_str, Priority.MEDIUM)
        
        # Questionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        questions = []
        for q_text in questions_raw:
            questions.append(
                Question(
                    text=q_text,
                    type="specification"
                )
            )
        
        # Contextã®ä½œæˆ
        context = Context(
            source_text=quoted_text if quoted_text else issue,
            surrounding_text=quoted_text if quoted_text else requirement_text[:100],
            line_number=1
        )
        
        # èª¬æ˜æ–‡ã®ç”Ÿæˆ
        description = explanation
        if missing_info:
            description += f"\nä¸è¶³æƒ…å ±: {', '.join(missing_info[:3])}"
        if risks:
            description += f"\nãƒªã‚¹ã‚¯: {risks[0]}"
        
        return UndefinedElement(
            id=f"LLM-AMB-{uuid.uuid4().hex[:8].upper()}",
            category=category,
            subcategory=category_raw,
            title=issue,
            description=description,
            questions=questions,
            detection=DetectionInfo(
                method="llm",
                confidence=0.8,
                reasoning=f"LLMï¼ˆ{self.model}ï¼‰ã«ã‚ˆã‚‹æ–‡è„ˆåˆ†æ"
            ),
            context=context,
            estimated_severity=priority
        )


class LLMQuestionGenerator:
    """å®Ÿè·µçš„ãªè³ªå•ã‚’ç”Ÿæˆã™ã‚‹LLMã‚¯ãƒ©ã‚¹"""
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ3: å®Ÿè·µçš„ãªè³ªå•ç”Ÿæˆç”¨
    SYSTEM_PROMPT = """ã‚ãªãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚æœªå®šç¾©è¦ç´ ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã«ç¢ºèªã™ã¹ãè³ªå•ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

è³ªå•ä½œæˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³:
1. å…·ä½“çš„ã§ç­”ãˆã‚„ã™ã„è³ªå•ã«ã™ã‚‹
2. Yes/Noã§ç­”ãˆã‚‰ã‚Œã‚‹ã‚‚ã®ã¨ã€å…·ä½“å€¤ã‚’æ±‚ã‚ã‚‹ã‚‚ã®ã‚’æ··åœ¨ã•ã›ã‚‹
3. å¯èƒ½ãªé™ã‚Šé¸æŠè‚¢ã‚’æç¤ºã™ã‚‹
4. èª°ã«èãã¹ãã‹ã‚’æ˜ç¤ºã™ã‚‹ï¼ˆãƒ“ã‚¸ãƒã‚¹å´ or æŠ€è¡“å´ï¼‰
5. å„ªå…ˆåº¦ã‚’ä»˜ã‘ã‚‹ï¼ˆcritical=ä»Šã™ã, high=æ—©ã‚ã«, medium=ä½™è£•ãŒã‚ã‚Œã°ï¼‰

å‡ºåŠ›å½¢å¼: JSON
{
  "questions": [
    {
      "id": "Q001",
      "question": "è³ªå•æ–‡ï¼ˆå…·ä½“çš„ã§ç­”ãˆã‚„ã™ã„å½¢å¼ï¼‰",
      "question_type": "yes_no | choice | numeric | text",
      "choices": ["é¸æŠè‚¢1", "é¸æŠè‚¢2", "é¸æŠè‚¢3"],
      "who_to_ask": "ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã‚ªãƒ¼ãƒŠãƒ¼ | ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ¼ãƒ€ãƒ¼ | ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ | ãƒ“ã‚¸ãƒã‚¹æ‹…å½“è€… | ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ‹…å½“è€…",
      "priority": "critical | high | medium | low",
      "reason": "ãªãœã“ã®è³ªå•ãŒé‡è¦ã‹ï¼ˆ50æ–‡å­—ç¨‹åº¦ï¼‰",
      "impact_if_not_answered": "ç­”ãˆã‚‰ã‚Œãªã‹ã£ãŸå ´åˆã®ãƒªã‚¹ã‚¯ï¼ˆ50æ–‡å­—ç¨‹åº¦ï¼‰"
    }
  ],
  "follow_up_scenarios": [
    {
      "condition": "ã‚‚ã—ã€œã‚’é¸ã‚“ã å ´åˆ",
      "additional_questions": [
        "è¿½åŠ ã§ç¢ºèªã™ã¹ãè³ªå•1",
        "è³ªå•2"
      ]
    }
  ]
}"""
    
    USER_PROMPT_TEMPLATE = """æœªå®šç¾©è¦ç´ :
- ã‚«ãƒ†ã‚´ãƒª: {category}
- ã‚¿ã‚¤ãƒˆãƒ«: {title}
- èª¬æ˜: {description}
- æ–‡è„ˆ: {context}

ã“ã®æœªå®šç¾©è¦ç´ ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"""
    
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o",
        max_cost: float = 1.00,
        timeout: int = 30
    ):
        """åˆæœŸåŒ–"""
        if not OPENAI_AVAILABLE:
            raise ImportError("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        
        self.client = OpenAI(api_key=api_key, timeout=timeout)
        self.model = model
        self.max_cost = max_cost
        self.timeout = timeout
        self.total_cost = 0.0
        self.call_count = 0
        
        self.price_per_1k_input = 0.005
        self.price_per_1k_output = 0.015
    
    def generate_questions(
        self,
        undefined_element: UndefinedElement
    ) -> List[Question]:
        """
        æœªå®šç¾©è¦ç´ ã«å¯¾ã™ã‚‹å®Ÿè·µçš„ãªè³ªå•ã‚’ç”Ÿæˆ
        
        Args:
            undefined_element: æœªå®šç¾©è¦ç´ 
        
        Returns:
            è³ªå•ã®ãƒªã‚¹ãƒˆ
        """
        # ã‚³ã‚¹ãƒˆä¸Šé™ãƒã‚§ãƒƒã‚¯
        if self.total_cost >= self.max_cost:
            print(f"âš ï¸  ã‚³ã‚¹ãƒˆä¸Šé™ï¼ˆ${self.max_cost}ï¼‰ã«é”ã—ãŸãŸã‚ã€è³ªå•ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return []
        
        try:
            start_time = time.time()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
            user_prompt = self.USER_PROMPT_TEMPLATE.format(
                category=undefined_element.category,
                title=undefined_element.title,
                description=undefined_element.description,
                context=undefined_element.context.surrounding_text
            )
            
            print(f"\nğŸ¤– LLMï¼ˆ{self.model}ï¼‰ã§å®Ÿè·µçš„ãªè³ªå•ã‚’ç”Ÿæˆä¸­...")
            
            # APIå‘¼ã³å‡ºã—
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.5,
                max_tokens=1500
            )
            
            elapsed_time = time.time() - start_time
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—
            content = response.choices[0].message.content
            
            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¨˜éŒ²
            usage = response.usage
            input_tokens = usage.prompt_tokens
            output_tokens = usage.completion_tokens
            
            # ã‚³ã‚¹ãƒˆã®è¨ˆç®—
            cost = (input_tokens / 1000 * self.price_per_1k_input +
                   output_tokens / 1000 * self.price_per_1k_output)
            self.total_cost += cost
            self.call_count += 1
            
            print(f"âœ“ å®Œäº†ï¼ˆ{elapsed_time:.1f}ç§’ï¼‰")
            print(f"  ã‚³ã‚¹ãƒˆ: ${cost:.4f} (ç´¯è¨ˆ: ${self.total_cost:.4f})")
            
            # JSONã®ãƒ‘ãƒ¼ã‚¹
            try:
                result = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON parseå¤±æ•—: {e}")
                return []
            
            # Questionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            questions = []
            for q_data in result.get("questions", []):
                question = Question(
                    text=q_data.get("question", ""),
                    type="specification",
                    suggested_answers=q_data.get("choices", [])
                )
                questions.append(question)
            
            print(f"âœ“ {len(questions)}å€‹ã®è³ªå•ã‚’ç”Ÿæˆ")
            
            return questions
        
        except Exception as e:
            print(f"âŒ LLMè³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
