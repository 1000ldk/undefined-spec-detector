"""
çµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼: Analysis Coordinator
å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã—ã¦ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®åˆ†æã‚’å®Ÿè¡Œ
"""
from typing import Optional, Dict, Any
from datetime import datetime

from usd.schema import InputDocument, ParsedRequirement, UndefinedElements
from usd.modules.requirement_parser import RequirementParser
from usd.modules.undefined_extractor import UndefinedExtractor


class AnalysisCoordinator:
    """åˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’çµ±åˆãƒ»èª¿æ•´ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.parser = RequirementParser()
        self.extractor = UndefinedExtractor()
        # Risk Analyzer ã¨ Remediation Advisor ã¯å°†æ¥å®Ÿè£…
    
    def analyze(
        self,
        content: str,
        metadata: Optional[Dict[str, Any]] = None,
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        è¦ä»¶æ–‡æ›¸ã‚’åˆ†æã™ã‚‹ï¼ˆãƒ•ãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼‰
        
        Args:
            content: è¦ä»¶æ–‡æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            options: åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
        
        Returns:
            çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ
        """
        # 1. å…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆ
        input_doc = InputDocument(
            content=content,
            metadata=metadata,
            options=options
        )
        
        # 2. Module 1: è¦ä»¶è§£æ
        print("ğŸ“ è¦ä»¶ã‚’è§£æä¸­...")
        parsed_req = self.parser.parse(input_doc)
        print(f"âœ“ {parsed_req.statistics.total_sentences}æ–‡ã‚’è§£æ")
        print(f"âœ“ {parsed_req.statistics.total_entities}å€‹ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æ¤œå‡º")
        print(f"âœ“ {parsed_req.statistics.total_actions}å€‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º")
        
        # 3. Module 2: æœªå®šç¾©è¦ç´ ã®æŠ½å‡º
        print("\nğŸ” æœªå®šç¾©è¦ç´ ã‚’æ¤œå‡ºä¸­...")
        undefined_elements = self.extractor.extract(parsed_req)
        print(f"âœ“ {undefined_elements.statistics['total_undefined']}å€‹ã®æœªå®šç¾©è¦ç´ ã‚’æ¤œå‡º")
        
        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        if undefined_elements.statistics.get('by_category'):
            print("\nã‚«ãƒ†ã‚´ãƒªåˆ¥:")
            for category, count in undefined_elements.statistics['by_category'].items():
                print(f"  - {category}: {count}ä»¶")
        
        # 4. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        report = self._create_comprehensive_report(
            input_doc,
            parsed_req,
            undefined_elements
        )
        
        return report
    
    def analyze_quick(self, content: str) -> UndefinedElements:
        """
        ã‚¯ã‚¤ãƒƒã‚¯åˆ†æï¼ˆæœªå®šç¾©è¦ç´ ã®ã¿ï¼‰
        
        Args:
            content: è¦ä»¶æ–‡æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            æœªå®šç¾©è¦ç´ ãƒªã‚¹ãƒˆ
        """
        input_doc = InputDocument(content=content)
        parsed_req = self.parser.parse(input_doc)
        undefined_elements = self.extractor.extract(parsed_req)
        return undefined_elements
    
    def _create_comprehensive_report(
        self,
        input_doc: InputDocument,
        parsed_req: ParsedRequirement,
        undefined_elements: UndefinedElements
    ) -> Dict[str, Any]:
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        return {
            "report_id": f"REPORT-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "generated_at": datetime.now().isoformat(),
            "system_version": "0.1.0",
            
            "input_document": {
                "content": input_doc.content,
                "length": len(input_doc.content),
            },
            
            "parsing_result": {
                "document_id": parsed_req.document_id,
                "sentences": len(parsed_req.sentences),
                "entities": len(parsed_req.entities),
                "actions": len(parsed_req.actions),
                "requirements": len(parsed_req.requirements),
                "statistics": {
                    "avg_completeness": parsed_req.statistics.avg_completeness_score,
                    "avg_ambiguity": parsed_req.statistics.avg_ambiguity_score,
                },
            },
            
            "undefined_elements": {
                "total": undefined_elements.statistics["total_undefined"],
                "by_category": undefined_elements.statistics.get("by_category", {}),
                "by_severity": undefined_elements.statistics.get("by_severity", {}),
                "elements": [
                    {
                        "id": elem.id,
                        "title": elem.title,
                        "category": elem.category,
                        "subcategory": elem.subcategory,
                        "description": elem.description,
                        "severity": elem.estimated_severity.value,
                        "questions": [q.text for q in elem.questions],
                        "confidence": elem.detection.confidence,
                    }
                    for elem in undefined_elements.undefined_elements
                ],
            },
            
            "executive_summary": self._generate_executive_summary(
                parsed_req,
                undefined_elements
            ),
            
            "meta_analysis": {
                "overall_completeness": undefined_elements.meta_analysis.overall_completeness if undefined_elements.meta_analysis else 0.0,
                "critical_gaps": undefined_elements.meta_analysis.critical_gaps if undefined_elements.meta_analysis else [],
                "recommendations": undefined_elements.meta_analysis.recommendations if undefined_elements.meta_analysis else [],
            }
        }
    
    def _generate_executive_summary(
        self,
        parsed_req: ParsedRequirement,
        undefined_elements: UndefinedElements
    ) -> Dict[str, Any]:
        """ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        total_undefined = undefined_elements.statistics["total_undefined"]
        high_risk_count = undefined_elements.statistics.get("by_severity", {}).get("high", 0)
        
        # å…¨ä½“çš„ãªè©•ä¾¡
        if parsed_req.statistics.avg_completeness_score >= 0.7:
            overall_assessment = "è‰¯å¥½"
        elif parsed_req.statistics.avg_completeness_score >= 0.5:
            overall_assessment = "è¦æ”¹å–„"
        else:
            overall_assessment = "ä¸ååˆ†"
        
        # ã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
        key_findings = []
        if total_undefined > 10:
            key_findings.append(f"{total_undefined}å€‹ã®æœªå®šç¾©è¦ç´ ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        if high_risk_count > 0:
            key_findings.append(f"ã†ã¡{high_risk_count}å€‹ã¯é«˜ãƒªã‚¹ã‚¯ã§ã™")
        if parsed_req.statistics.avg_ambiguity_score > 0.6:
            key_findings.append("æ›–æ˜§ãªè¡¨ç¾ãŒå¤šãå«ã¾ã‚Œã¦ã„ã¾ã™")
        
        return {
            "overall_assessment": overall_assessment,
            "key_findings": key_findings,
            "total_undefined": total_undefined,
            "high_risk_count": high_risk_count,
        }



