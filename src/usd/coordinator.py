"""
çµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼: Analysis Coordinator v2.0
å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã—ã¦ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®åˆ†æã‚’å®Ÿè¡Œï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé§†å‹•å‹ï¼‰
"""
from typing import Optional, Dict, Any
from datetime import datetime

from usd.schema import InputDocument, ParsedRequirement, UndefinedElements
from usd.modules.requirement_parser import RequirementParser
from usd.modules.undefined_extractor import UndefinedExtractor
from usd.modules.action_classifier import ActionTypeClassifier


class AnalysisCoordinator:
    """åˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’çµ±åˆãƒ»èª¿æ•´ã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆv2.1 - LLMçµ±åˆï¼‰"""
    
    def __init__(self, use_llm: bool = False, api_key: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            use_llm: LLMã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
            api_key: OpenAI API Keyï¼ˆuse_llm=Trueã®å ´åˆã«å¿…è¦ï¼‰
        """
        self.parser = RequirementParser()
        self.extractor = UndefinedExtractor(use_llm=use_llm, api_key=api_key)
        self.classifier = ActionTypeClassifier()
        # Risk Analyzer ã¨ Remediation Advisor ã¯å°†æ¥å®Ÿè£…
        self.use_llm = use_llm
    
    def analyze(
        self,
        content: str,
        metadata: Optional[Dict[str, Any]] = None,
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        è¦ä»¶æ–‡æ›¸ã‚’åˆ†æã™ã‚‹ï¼ˆãƒ•ãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ v2.0ï¼‰
        
        Args:
            content: è¦ä»¶æ–‡æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            options: åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
        
        Returns:
            çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ
        """
        # 1. å…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆ
        input_doc = InputDocument(
            content=content,
            metadata=metadata,
            options=options
        )
        
        # ã€æ–°æ©Ÿèƒ½ã€‘1.5. å‡¦ç†ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡
        print("ğŸ¯ å‡¦ç†ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡ä¸­...")
        classification = self.classifier.classify(content)
        print(f"âœ“ å‡¦ç†ã‚¿ã‚¤ãƒ—: {classification.action_type.value}")
        print(f"âœ“ ä¿¡é ¼åº¦: {classification.confidence:.0%}")
        print(f"âœ“ åŸºæœ¬å±é™ºåº¦: {classification.base_severity}")
        if classification.detected_entities:
            print(f"âœ“ æ¤œå‡ºã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {', '.join(classification.detected_entities)}")
        
        # 2. Module 1: è¦ä»¶è§£æ
        print("\nğŸ“ è¦ä»¶ã‚’è§£æä¸­...")
        parsed_req = self.parser.parse(input_doc)
        print(f"âœ“ {parsed_req.statistics.total_sentences}æ–‡ã‚’è§£æ")
        print(f"âœ“ {parsed_req.statistics.total_entities}å€‹ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æ¤œå‡º")
        print(f"âœ“ {parsed_req.statistics.total_actions}å€‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º")
        
        # 3. Module 2: æœªå®šç¾©è¦ç´ ã®æŠ½å‡ºï¼ˆv2.1 - LLMçµ±åˆå‹ï¼‰
        print("\nğŸ” æœªå®šç¾©è¦ç´ ã‚’æ¤œå‡ºä¸­...")
        if self.use_llm:
            print("   ï¼ˆLLMãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹ï¼‰")
        undefined_elements = self.extractor.extract(parsed_req)
        print(f"âœ“ {undefined_elements.statistics['total_undefined']}å€‹ã®æœªå®šç¾©è¦ç´ ã‚’æ¤œå‡º")
        
        # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤ºï¼ˆè‡´å‘½åº¦åˆ¥ï¼‰
        if undefined_elements.undefined_elements:
            print("\nğŸ“Š è‡´å‘½åº¦åˆ¥:")
            critical_count = sum(1 for e in undefined_elements.undefined_elements 
                               if e.criticality_info and "ğŸ”´" in e.criticality_info.get("level", ""))
            warning_count = sum(1 for e in undefined_elements.undefined_elements 
                              if e.criticality_info and "ğŸŸ¡" in e.criticality_info.get("level", ""))
            ok_count = sum(1 for e in undefined_elements.undefined_elements 
                          if e.criticality_info and "ğŸŸ¢" in e.criticality_info.get("level", ""))
            
            if critical_count > 0:
                print(f"  ğŸ”´ ç€æ‰‹ä¸å¯: {critical_count}ä»¶")
            if warning_count > 0:
                print(f"  ğŸŸ¡ è¦ç¢ºèª: {warning_count}ä»¶")
            if ok_count > 0:
                print(f"  ğŸŸ¢ å¾Œæ±ºã‚OK: {ok_count}ä»¶")
            
            # ğŸ†• æ¤œå‡ºæ–¹æ³•åˆ¥ã®è¡¨ç¤º
            if "by_method" in undefined_elements.statistics:
                print("\næ¤œå‡ºæ–¹æ³•åˆ¥:")
                for method, count in undefined_elements.statistics["by_method"].items():
                    method_name = {
                        "rule_based": "ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹",
                        "template_driven": "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
                        "llm": "LLM",
                        "semantic_analysis": "æ„å‘³è§£æ",
                        "pattern_matching": "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ"
                    }.get(method, method)
                    print(f"  - {method_name}: {count}ä»¶")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®è¡¨ç¤º
        if undefined_elements.statistics.get('by_category'):
            print("\nã‚«ãƒ†ã‚´ãƒªåˆ¥:")
            for category, count in undefined_elements.statistics['by_category'].items():
                print(f"  - {category}: {count}ä»¶")
        
        # 4. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        report = self._create_comprehensive_report(
            input_doc,
            parsed_req,
            undefined_elements,
            classification
        )
        
        return report
    
    def analyze_quick(self, content: str) -> UndefinedElements:
        """
        ã‚¯ã‚¤ãƒƒã‚¯åˆ†æï¼ˆæœªå®šç¾©è¦ç´ ã®ã¿ï¼‰
        
        Args:
            content: è¦ä»¶æ–‡æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            æœªå®šç¾©è¦ç´ ãƒªã‚¹ãƒˆ
        """
        input_doc = InputDocument(content=content)
        parsed_req = self.parser.parse(input_doc)
        undefined_elements = self.extractor.extract(parsed_req)
        return undefined_elements
    
    def _create_comprehensive_report(
        self,
        input_doc: InputDocument,
        parsed_req: ParsedRequirement,
        undefined_elements: UndefinedElements,
        classification=None
    ) -> Dict[str, Any]:
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆï¼ˆv2.0ï¼‰"""
        # è‡´å‘½åº¦åˆ¥ã®é›†è¨ˆ
        criticality_stats = {
            "must_define": 0,
            "should_confirm": 0,
            "can_decide_later": 0
        }
        
        for elem in undefined_elements.undefined_elements:
            if elem.criticality_info:
                level = elem.criticality_info.get("level", "")
                if "ğŸ”´" in level:
                    criticality_stats["must_define"] += 1
                elif "ğŸŸ¡" in level:
                    criticality_stats["should_confirm"] += 1
                elif "ğŸŸ¢" in level:
                    criticality_stats["can_decide_later"] += 1
        
        return {
            "report_id": f"REPORT-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "generated_at": datetime.now().isoformat(),
            "system_version": "2.1.0-hybrid",  # ğŸ†• ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°
            
            "input_document": {
                "content": input_doc.content,
                "length": len(input_doc.content),
            },
            
            # ã€æ–°æ©Ÿèƒ½ã€‘å‡¦ç†ã‚¿ã‚¤ãƒ—æƒ…å ±
            "action_classification": {
                "action_type": classification.action_type.value if classification else "UNKNOWN",
                "confidence": classification.confidence if classification else 0.0,
                "base_severity": classification.base_severity if classification else "UNKNOWN",
                "detected_entities": classification.detected_entities if classification else [],
                "matched_keywords": classification.matched_keywords if classification else []
            } if classification else None,
            
            "parsing_result": {
                "document_id": parsed_req.document_id,
                "sentences": len(parsed_req.sentences),
                "entities": len(parsed_req.entities),
                "actions": len(parsed_req.actions),
                "requirements": len(parsed_req.requirements),
                "statistics": {
                    "avg_completeness": parsed_req.statistics.avg_completeness_score,
                    "avg_ambiguity": parsed_req.statistics.avg_ambiguity_score,
                },
            },
            
            "undefined_elements": {
                "total": undefined_elements.statistics["total_undefined"],
                "by_category": undefined_elements.statistics.get("by_category", {}),
                "by_severity": undefined_elements.statistics.get("by_severity", {}),
                # ã€æ–°æ©Ÿèƒ½ã€‘è‡´å‘½åº¦åˆ¥ã®é›†è¨ˆ
                "by_criticality": criticality_stats,
                "elements": [
                    {
                        "id": elem.id,
                        "title": elem.title,
                        "category": elem.category,
                        "subcategory": elem.subcategory,
                        "description": elem.description,
                        "severity": elem.estimated_severity.value,
                        "questions": [q.text for q in elem.questions],
                        "confidence": elem.detection.confidence,
                        # ã€æ–°æ©Ÿèƒ½ã€‘è‡´å‘½åº¦æƒ…å ±
                        "criticality": elem.criticality_info if elem.criticality_info else None
                    }
                    for elem in undefined_elements.undefined_elements
                ],
            },
            
            "executive_summary": self._generate_executive_summary(
                parsed_req,
                undefined_elements,
                criticality_stats
            ),
            
            "meta_analysis": {
                "overall_completeness": undefined_elements.meta_analysis.overall_completeness if undefined_elements.meta_analysis else 0.0,
                "critical_gaps": undefined_elements.meta_analysis.critical_gaps if undefined_elements.meta_analysis else [],
                "recommendations": undefined_elements.meta_analysis.recommendations if undefined_elements.meta_analysis else [],
            }
        }
    
    def _generate_executive_summary(
        self,
        parsed_req: ParsedRequirement,
        undefined_elements: UndefinedElements,
        criticality_stats: Dict[str, int] = None
    ) -> Dict[str, Any]:
        """ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆï¼ˆv2.0ï¼‰"""
        total_undefined = undefined_elements.statistics["total_undefined"]
        high_risk_count = undefined_elements.statistics.get("by_severity", {}).get("high", 0)
        
        # è‡´å‘½åº¦ã«åŸºã¥ãè©•ä¾¡
        if criticality_stats:
            must_define_count = criticality_stats.get("must_define", 0)
            should_confirm_count = criticality_stats.get("should_confirm", 0)
        else:
            must_define_count = 0
            should_confirm_count = 0
        
        # å…¨ä½“çš„ãªè©•ä¾¡
        if must_define_count > 0:
            overall_assessment = "ç€æ‰‹ä¸å¯ï¼ˆæœªå®šç¾©è§£æ±ºãŒå¿…é ˆï¼‰"
            assessment_level = "CRITICAL"
        elif should_confirm_count > 5:
            overall_assessment = "è¦ç¢ºèªäº‹é …ãŒå¤šã„"
            assessment_level = "HIGH"
        elif parsed_req.statistics.avg_completeness_score >= 0.7:
            overall_assessment = "è‰¯å¥½"
            assessment_level = "GOOD"
        elif parsed_req.statistics.avg_completeness_score >= 0.5:
            overall_assessment = "è¦æ”¹å–„"
            assessment_level = "MEDIUM"
        else:
            overall_assessment = "ä¸ååˆ†"
            assessment_level = "LOW"
        
        # ã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
        key_findings = []
        if must_define_count > 0:
            key_findings.append(f"ğŸ”´ ç€æ‰‹ä¸å¯é …ç›®ãŒ{must_define_count}å€‹ã‚ã‚Šã¾ã™ã€‚å®Ÿè£…é–‹å§‹å‰ã«å¿…ãšè§£æ±ºã—ã¦ãã ã•ã„")
        if should_confirm_count > 0:
            key_findings.append(f"ğŸŸ¡ ç¢ºèªæ¨å¥¨é …ç›®ãŒ{should_confirm_count}å€‹ã‚ã‚Šã¾ã™")
        if total_undefined > 10:
            key_findings.append(f"{total_undefined}å€‹ã®æœªå®šç¾©è¦ç´ ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        if high_risk_count > 0:
            key_findings.append(f"ã†ã¡{high_risk_count}å€‹ã¯é«˜ãƒªã‚¹ã‚¯ã§ã™")
        if parsed_req.statistics.avg_ambiguity_score > 0.6:
            key_findings.append("æ›–æ˜§ãªè¡¨ç¾ãŒå¤šãå«ã¾ã‚Œã¦ã„ã¾ã™")
        
        return {
            "overall_assessment": overall_assessment,
            "assessment_level": assessment_level,
            "key_findings": key_findings,
            "total_undefined": total_undefined,
            "high_risk_count": high_risk_count,
            "must_define_count": must_define_count,
            "should_confirm_count": should_confirm_count,
        }



